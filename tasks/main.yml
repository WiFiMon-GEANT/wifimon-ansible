---
- name: Print error if not supported linux distribution is used for WAS installation
  fail: msg="You are trying to install WAS on not supported linux distribution. Please read the README file for details"
  when:
    - ansible_distribution_release != 'noble'
    - ansible_distribution_release != 'jammy'
    - ansible_distribution_release != 'focal'
    - ansible_distribution_release != 'bullseye'
    - ansible_distribution_release != 'bookworm'

- name: Print error if ansible versions is not equal or greater than 2.10.0
  fail: msg="Your ansible versions is older than 2.10.0. Ansible version 2.10 or greater is requred to run this playbook. Please read the README file for details"
  when: ansible_version.full is version('2.10.0', '<', strict=True)

- name: Print error if not enough CPU/RAM resources available on target server
  fail: msg="You are trying to install WAS on server with lower CPU/RAM resources than required. Please read the README file for details"
  when: (ansible_processor_nproc < 4) or (ansible_memtotal_mb <= 7800)

- name: Break if elasticsearch_kibana_version variable is set and elasticsearch/kibana version is less then 8.0 or greater than 9.0
  fail: msg="Elasticsearch/kibana version you defined in var/main.yml is not higher than 8.0 and lower than 9.0."
  when: elasticsearch_kibana_version is defined and (elasticsearch_kibana_version is version('8.0', '<', strict=True) or elasticsearch_kibana_version is version('9.0', '>=', strict=True))

- name: Ensure dig and gpg are installed
  apt:
    update_cache: yes
    name:
      - dnsutils
      - gpg
    state: present
  register: dnsutils_gpg_install_result
  until: dnsutils_gpg_install_result is not failed
  retries: 30
  delay: 20

- name: Get WAS servers public IP
  uri:
    url: http://whatismyip.akamai.com
    method: GET
    timeout: 8
    return_content: yes
  changed_when: false
  register: public_ip
  until: public_ip.status == 200
  retries: 3
  delay: 10

- name: Resolve A record for {{ was_server_hostname }}.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}.{{ was_server_domainname }}
  register: was_dns_record

- name: Resolve A record for {{ was_server_hostname }}-ui.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-ui.{{ was_server_domainname }}
  register: was_ui_dns_record

- name: Resolve A record for {{ was_server_hostname }}-elastic.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-elastic.{{ was_server_domainname }}
  register: was_elastic_dns_record

- name: Resolve A record for {{ was_server_hostname }}-kibana.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-kibana.{{ was_server_domainname }}
  register: was_kibana_dns_record

- name: Resolve A record for {{ was_server_hostname }}-flask.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-flask.{{ was_server_domainname }}
  register: was_flask_dns_record

- name: Resolve A record for {{ was_server_hostname }}-anomaly.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-anomaly.{{ was_server_domainname }}
  register: was_anomaly_dns_record

- name: Resolve A record for {{ was_server_hostname }}-looking-glass.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-looking-glass.{{ was_server_domainname }}
  register: was_looking_glass_dns_record

- name: Resolve A record for {{ was_server_hostname }}-probe-state.{{ was_server_domainname }}
  shell: |
    dig +short {{ was_server_hostname }}-probe-state.{{ was_server_domainname }}
  register: was_probe_state_dns_record

- name: Resolve A record for {{ wts_server_hostname }}.{{ was_server_domainname }}
  shell: |
    dig +short {{ wts_server_hostname }}.{{ was_server_domainname }}
  register: wts_dns_record

- name: Break if no DNS record found for WAS FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-UI FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-ui.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_ui_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-ELASTIC FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-elastic.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_elastic_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-KIBANA FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-kibana.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_kibana_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-FLASK FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-flask.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_flask_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-ANOMALY FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-anomaly.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_anomaly_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-LOOKING-GLASS FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-looking-glass.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_looking_glass_dns_record.stdout != public_ip.content

- name: Print error if no or wrong DNS record found for WAS-PROBE-STATE FQDN
  fail: msg="There is no or wrong DNS record for {{ was_server_hostname }}-probe-state.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: was_probe_state_dns_record.stdout != public_ip.content

- name: Break if no DNS record found for WTS FQDN
  fail: msg="There is no or wrong DNS record for {{ wts_server_hostname }}.{{ was_server_domainname }}. It must be resolve to {{ public_ip.stdout }} which is not the case. Please read README for requirements"
  when: wts_dns_record.stdout != public_ip.content

- name: Set a FQDN hostname
  hostname:
    name: "{{ was_server_hostname }}"

- name: Check cloud-init file exists
  stat:
    path: /etc/cloud/cloud.cfg
  register: cloud_cfg_file

- name: Do not manage etc_hosts from cloud-init
  lineinfile:
    path: /etc/cloud/cloud.cfg
    regexp: "{{ item }}"
    state: absent
  with_items:
    - 'manage_etc_hosts'
    - 'update_etc_hosts'
    - 'update_hostname'
    - 'set_hostname'
  when: cloud_cfg_file.stat.exists

- name: Add PostgreSQL apt signing key
  apt_key:
    url: https://www.postgresql.org/media/keys/ACCC4CF8.asc
    state: present
    keyring: /etc/apt/trusted.gpg.d/pgdg.gpg

- name: Add PostgreSQL apt repo
  apt_repository:
    repo: deb http://apt.postgresql.org/pub/repos/apt/ {{ ansible_distribution_release }}-pgdg main
    state: present
    filename: pgdg
    update_cache: false

- name: Add elsaticsearch apt signing key
  apt_key:
    url: https://artifacts.elastic.co/GPG-KEY-elasticsearch
    state: present
    keyring: /etc/apt/trusted.gpg.d/elasticsearch.gpg

- name: Add elasticsearch 8.x apt repo
  apt_repository:
    repo: deb https://artifacts.elastic.co/packages/8.x/apt stable main
    state: present
    filename: elastic-8.x

- name: Add Saltstack apt signing key to Ubuntu
  apt_key:
    url: https://repo.saltproject.io/salt/py3/{{ ansible_distribution | lower }}/{{ ansible_distribution_version }}/amd64/SALT-PROJECT-GPG-PUBKEY-2023.gpg
    state: present
    keyring: /etc/apt/trusted.gpg.d/salt-archive-keyring.gpg
  when: ansible_distribution_release == 'jammy' or ansible_distribution_release == 'focal' or ansible_distribution_release == 'noble'

- name: Add Saltstack apt repo to Ubuntu
  apt_repository:
    repo: deb [signed-by=/etc/apt/trusted.gpg.d/salt-archive-keyring.gpg arch=amd64] https://repo.saltproject.io/salt/py3/{{ ansible_distribution | lower }}/{{ ansible_distribution_version }}/amd64/latest {{ ansible_distribution_release }} main
    state: present
    filename: salt
    update_cache: false
  when: ansible_distribution_release == 'jammy' or ansible_distribution_release == 'focal' or ansible_distribution_release == 'noble'

- name: Add Saltstack apt signing key to Debian
  apt_key:
    url: https://repo.saltproject.io/salt/py3/{{ ansible_distribution | lower }}/{{ ansible_distribution_major_version }}/amd64/SALT-PROJECT-GPG-PUBKEY-2023.gpg
    state: present
    keyring: /etc/apt/trusted.gpg.d/salt-archive-keyring.gpg
  when: ansible_distribution_release == 'bullseye' or ansible_distribution_release == 'bookworm'

- name: Add Saltstack apt repo to Debian
  apt_repository:
    repo: deb [signed-by=/etc/apt/trusted.gpg.d/salt-archive-keyring.gpg arch=amd64] https://repo.saltproject.io/salt/py3/{{ ansible_distribution | lower }}/{{ ansible_distribution_major_version }}/amd64/latest {{ ansible_distribution_release }} main
    state: present
    filename: salt
    update_cache: false
  when: ansible_distribution_release == 'bullseye' or ansible_distribution_release == 'bookworm'

- name: Install system updates
  apt:
    upgrade: dist
    update_cache: true
    dpkg_options: 'force-confold,force-confdef'

- name: Ensure all required packages are installed
  apt:
    update_cache: false
    name: 
      - postgresql-{{ postgresql_version }}
      - openjdk-17-jre-headless
      - curl
      - nginx
      - libnginx-mod-stream
      - certbot
      - acl
      - python3-certbot-nginx
      - python3-minimal
      - python3-psycopg2
      - python3-bcrypt
      - python3-flask
      - python3-dotenv
      - python3-matplotlib
      - python3-pandas
      - python3-numpy
      - python3-urllib3
      - python3-pip
      - python3-virtualenv
      - salt-master
      - unzip
    state: present
    dpkg_options: 'force-confold,force-confdef'

- name: Install elasticsearch-8 python package 
  shell: |
    PIP_BREAK_SYSTEM_PACKAGES=1 pip install elasticsearch==8.10

- name: Enable and start salt-master service
  systemd:
    daemon_reload: yes
    name: salt-master
    state: started
    enabled: yes

- name: Find latest minor verions of elasticsearch/kibana if elasticsearch_kibana_version variable is set and no minor version specified
  shell: |
    apt-cache madison elasticsearch | grep {{ elasticsearch_kibana_version }} | head -n1 | awk -F"|" '{print $2}' | tr -d ' '
  register: elasticsearch_kibana_version_latest
  when: elasticsearch_kibana_version is defined

- name: Find latest minor verions of logstash if elasticsearch_kibana_version variable is set and no minor version specified
  shell: |
    apt-cache madison logstash | grep {{ elasticsearch_kibana_version }} | head -n1 | awk -F"|" '{print $2}' | tr -d ' '
  register: logstash_version_latest
  when: elasticsearch_kibana_version is defined

- name: Install elasticsearch/kibana/logstash specific versions if elasticsearch_kibana_version variable is set
  apt:
    update_cache: false
    name:
      - elasticsearch={{ elasticsearch_kibana_version_latest.stdout }}
      - kibana={{ elasticsearch_kibana_version_latest.stdout }}
      - logstash={{ logstash_version_latest.stdout }}
    state: present
    dpkg_options: 'force-confold,force-confdef'
  when: elasticsearch_kibana_version is defined

- name: Prevent elasticsearch/kibana packages from being upgraded if elasticsearch_kibana_version variable is set
  dpkg_selections:
    name: "{{ item }}"
    selection: hold
  with_items:
    - elasticsearch
    - kibana
    - logstash
  when: elasticsearch_kibana_version is defined

- name: Install latest elasticsearch/kibana 8.x versions if elasticsearch_kibana_version variable is not set
  apt:
    update_cache: false
    name:
      - elasticsearch
      - kibana
      - logstash
    state: present
  when: elasticsearch_kibana_version is not defined

- name: Install wifimon-agent package
  apt:
    deb: https://s3.grena.ge/wifimon-agent/wifimon-agent-{{ wifimon_agent_version }}.deb
    dpkg_options: 'force-confold,force-confdef'

- name: Remove useless packages from the cache
  apt:
    autoclean: yes

- name: Remove dependencies that are no longer required
  apt:
    autoremove: yes

- name: Create WTS nginx document_root
  file:
    path: /var/www/wts/wifimon
    state: directory
    mode: '0755'

- name: Download WTS zip file
  get_url:
    url: https://s3.grena.ge/wts/wts.zip
    dest: /tmp/wts.zip

- name: Unzip WTS zip file
  unarchive:
    src: /tmp/wts.zip
    dest: /var/www/wts/wifimon
    remote_src: yes

- name: Find and register all files in /var/www/wts/wifimon to replace WTS_FQDN with {{ wts_server_hostname }}.{{ was_server_domainname }}
  find:
    path: /var/www/wts/wifimon/
    file_type: file
    recurse: yes
  register: wts_files

- name: Replace WTS_FQDN string with {{ wts_server_hostname }}.{{ was_server_domainname }} in WTS files
  replace:
    path: "{{ item.path }}"
    regexp: 'WTS_FQDN'
    replace: "{{ wts_server_hostname }}.{{ was_server_domainname }}"
    backup: no
  with_items: "{{ wts_files.files }}"
  no_log: true

- name: Replace WAS_FQDN string with {{ was_server_hostname }}.{{ was_server_domainname }} in WTS files
  replace:
    path: "{{ item.path }}"
    regexp: 'WAS_FQDN'
    replace: "{{ was_server_hostname }}.{{ was_server_domainname }}"
    backup: no
  with_items: "{{ wts_files.files }}"
  no_log: true

- name: Copy probe-config directory
  copy:
    src: files/probe-config
    dest: /root
    owner: root
    group: root
    directory_mode: '0755'

- name: Copy alarm directory
  copy:
    src: files/alarm
    dest: /root
    owner: root
    group: root
    directory_mode: '0755'

- name: Copy looking-glass directory
  copy:
    src: files/looking-glass
    dest: /root
    owner: root
    group: root
    directory_mode: '0755'

- name: Copy probe-state directory
  copy:
    src: files/probe-state
    dest: /root
    owner: root
    group: root
    directory_mode: '0755'

- name: Install dash into the /root/looking-glass (virtualenv)
  pip:
    name: dash
    virtualenv: /root/looking-glass

- name: Install dash into the /root/probe-state (virtualenv)
  pip:
    name: dash
    virtualenv: /root/probe-state

- name: Copy all configuration files
  template:
    src: '{{ item.src }}'
    dest: '{{ item.dest }}'
    owner: '{{ item.owner }}'
    group: '{{ item.group }}'
    mode: '{{ item.mode }}'
  loop:
    - { src: 'was-proxy.conf.j2', dest: '/etc/nginx/sites-available/was-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'elastic-proxy.conf.j2', dest: '/etc/nginx/sites-available/elastic-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'kibana-proxy.conf.j2', dest: '/etc/nginx/sites-available/kibana-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'was-ui-proxy.conf.j2', dest: '/etc/nginx/sites-available/was-ui-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'flask-proxy.conf.j2', dest: '/etc/nginx/sites-available/flask-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'was-looking-glass-proxy.conf.j2', dest: '/etc/nginx/sites-available/was-looking-glass-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'was-probe-state-proxy.conf.j2', dest: '/etc/nginx/sites-available/was-probe-state-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'anomaly-proxy.conf.j2', dest: '/etc/nginx/sites-available/anomaly-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'wts.conf.j2', dest: '/etc/nginx/sites-available/wts.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'logstash-stream-proxy.conf.j2', dest: '/etc/nginx/sites-available/logstash-stream-proxy.conf', owner: 'root', group: 'root', mode: '0664' }
    - { src: 'hosts.j2', dest: '/etc/hosts', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'app.py.j2', dest: '/root/probe-config/app.py', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'probe-config-secret.j2', dest: '/root/probe-config/.env', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'wts_info.txt.j2', dest: '/root/looking-glass/wts_info.txt', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'anomaly-secret.j2', dest: '/root/alarm/.env', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'wifimon_database.sql.j2', dest: '/tmp/wifimon_database.sql', owner: 'postgres', group: 'postgres', mode: '0600'  }
    - { src: 'elasticsearch.yml.j2', dest: '/etc/elasticsearch/elasticsearch.yml', owner: 'root', group: 'elasticsearch', mode: '0660'  }
    - { src: 'instances.yml.j2', dest: '/usr/share/elasticsearch/instances.yml', owner: 'root', group: 'elasticsearch', mode: '0660'  }
    - { src: 'kibana.yml.j2', dest: '/etc/kibana/kibana.yml', owner: 'root', group: 'kibana', mode: '0660'  }
    - { src: 'logstash.yml.j2', dest: '/etc/logstash/logstash.yml', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'pipelines.yml.j2', dest: '/etc/logstash/pipelines.yml', owner: 'root', group: 'root', mode: '0664'  }
    - { src: 'beats-pipeline.conf.j2', dest: '/etc/logstash/conf.d/beats-pipeline.conf', owner: 'root', group: 'logstash', mode: '0660'  }
    - { src: 'radius-pipeline.conf.j2', dest: '/etc/logstash/conf.d/radius-pipeline.conf', owner: 'root', group: 'logstash', mode: '0660'  }
    - { src: 'dhcp-pipeline.conf.j2', dest: '/etc/logstash/conf.d/dhcp-pipeline.conf', owner: 'root', group: 'logstash', mode: '0660'  }
    - { src: 'ui.properties.j2', dest: '/usr/lib/wifimon/config/ui.properties', owner: 'wifimon', group: 'root', mode: '0640'  }
    - { src: 'secure-processor.properties.j2', dest: '/usr/lib/wifimon/config/secure-processor.properties', owner: 'wifimon', group: 'root', mode: '0640'  }

- name: Enable nginx configuration files
  file:
    src: '{{ item.src }}'
    dest: '{{ item.dest }}'
    owner: root
    group: root
    state: link
  loop:
    - { src: '/etc/nginx/sites-available/was-proxy.conf', dest: '/etc/nginx/sites-enabled/was-proxy.conf' }
    - { src: '/etc/nginx/sites-available/elastic-proxy.conf', dest: '/etc/nginx/sites-enabled/elastic-proxy.conf' }
    - { src: '/etc/nginx/sites-available/kibana-proxy.conf', dest: '/etc/nginx/sites-enabled/kibana-proxy.conf' }
    - { src: '/etc/nginx/sites-available/was-ui-proxy.conf', dest: '/etc/nginx/sites-enabled/was-ui-proxy.conf' }
    - { src: '/etc/nginx/sites-available/flask-proxy.conf', dest: '/etc/nginx/sites-enabled/flask-proxy.conf' }
    - { src: '/etc/nginx/sites-available/anomaly-proxy.conf', dest: '/etc/nginx/sites-enabled/anomaly-proxy.conf' }
    - { src: '/etc/nginx/sites-available/wts.conf', dest: '/etc/nginx/sites-enabled/wts.conf' }
    - { src: '/etc/nginx/sites-available/was-looking-glass-proxy.conf', dest: '/etc/nginx/sites-enabled/was-looking-glass-proxy.conf' }
    - { src: '/etc/nginx/sites-available/was-probe-state-proxy.conf', dest: '/etc/nginx/sites-enabled/was-probe-state-proxy.conf' }

- name: Disable nginx default config
  file:
    path: /etc/nginx/sites-enabled/default
    state: absent

- name: Reload nginx service
  service:
    name: nginx
    enabled: yes
    state: reloaded

- name: Obtain letsencrypt certificate
  shell: |
    certbot --nginx --non-interactive --agree-tos --redirect -m "{{ letsencrypt_admin_email }}" -d "{{ was_server_hostname }}"."{{ was_server_domainname }}" -d "{{ was_server_hostname }}"-elastic."{{ was_server_domainname }}" -d "{{ was_server_hostname }}"-kibana."{{ was_server_domainname }}" -d "{{ was_server_hostname }}"-ui."{{ was_server_domainname }}" -d "{{ was_server_hostname }}"-flask."{{ was_server_domainname }}" -d "{{ was_server_hostname }}"-anomaly."{{ was_server_domainname }}" -d "{{ wts_server_hostname }}.{{ was_server_domainname }}" -d {{ was_server_hostname }}-looking-glass.{{ was_server_domainname }} -d {{ was_server_hostname }}-probe-state.{{ was_server_domainname }}

- name: Grant user logstash read access to the directories in /etc/letsencrypt/
  acl:
    path: /etc/letsencrypt/{{ item }}
    entity: logstash
    etype: user
    permissions: rx
    state: present
  with_items:
    - live
    - archive

- name: Grant user logstash read access to a file /etc/letsencrypt/live/{{ was_server_hostname }}.{{ was_server_domainname }}/privkey.pem
  acl:
    path: /etc/letsencrypt/live/{{ was_server_hostname }}.{{ was_server_domainname }}/privkey.pem
    entity: logstash
    etype: user
    permissions: r
    state: present

- name: Create PostgreSQL user for wifimon database 
  postgresql_user:
    name: "{{ wifimon_database_user }}"
    password: "{{ wifimon_database_user_pass }}"
  become: true
  become_user: postgres

- name: Create PostgreSQL database for wifimon
  postgresql_db:
    name: "{{ wifimon_database_name }}"
    owner: "{{ wifimon_database_user }}"
    encoding: "UTF-8"
    lc_collate: "en_US.UTF-8"
    lc_ctype: "en_US.UTF-8"
    template: template0
  become: true
  become_user: postgres

- name: Import wifimon database schema
  postgresql_db:
    name: "{{ wifimon_database_name }}"
    login_user: "{{ wifimon_database_user }}"
    login_password: "{{ wifimon_database_user_pass }}"
    login_host: "{{ wifimon_database_host }}"
    state: restore
    target: /tmp/wifimon_database.sql

- name: Remove wifimon database dump file
  file:
    path: /tmp/wifimon_database.sql
    state: absent

- name: Generate wifimon admin account password bcrypt hash
  command:
    cmd: |
        python3 -c 'import bcrypt; print(bcrypt.hashpw(b"{{ wifimon_admin_pass }}", bcrypt.gensalt(rounds=15)).decode("ascii"))'
  register: wifimon_admin_pass_hash

- name: Create wifimon admin account
  command: psql -c "INSERT INTO users VALUES ('1', '{{ wifimon_admin_email }}', '{{ wifimon_admin_pass_hash.stdout }}', 'ADMIN');"
  environment:
    PGUSER: "{{ wifimon_database_user }}"
    PGDATABASE: "{{ wifimon_database_name }}"
    PGHOST: "{{ wifimon_database_host }}"
    PGPASSWORD: "{{ wifimon_database_user_pass }}"

- name: Generate random bootstrap password for elasticsearch
  shell: |
    openssl rand -hex 24
  register: elasticsearch_bootstrap_password

- name: Set elasticsearch bootstrap password
  shell: |
    echo -n "{{ elasticsearch_bootstrap_password.stdout }}" | /usr/share/elasticsearch/bin/elasticsearch-keystore add bootstrap.password -xf

- name: Enable and start elasticsearch service
  service:
    name: elasticsearch
    enabled: yes
    state: started
  register: elastic_service_status
  until: elastic_service_status is not failed
  delay: 30
  retries: 2

- name: Wait for elasticsearch service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_cluster/health'
    user: elastic
    password: "{{ elasticsearch_bootstrap_password.stdout }}"
    method: GET
    force_basic_auth: yes
    timeout: 10
    status_code: 200
  register: elastic_status
  until: elastic_status.status == 200
  delay: 30
  retries: 3
  no_log: true

- name: Change password for elastic builtin user
  uri:
    url: https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_security/user/elastic/_password
    user: elastic
    password: "{{ elasticsearch_bootstrap_password.stdout }}"
    method: PUT
    body: '{"password":"{{ elastic_elasticsearch_password }}"}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Set kibana_system password for elasticsearch
  uri:
    url: https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_security/user/kibana_system/_password
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"password":"{{ kibana_elasticsearch_password }}"}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Set logstash_system password for elasticsearch
  uri:
    url: https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_security/user/logstash_system/_password
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"password":"{{ logstash_system_user_password }}"}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Create radiuslogs/dhcplogs indices in elasticsearch
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/{{ item }}?pretty'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"settings" : {"index" : {"number_of_shards" : 3, "number_of_replicas" : 0 }}}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  with_items:
    - radiuslogs
    - dhcplogs
  no_log: true

- name: Create logstash_writer role in elasticsearch
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_security/role/logstash_writer_role?pretty'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: POST
    body: '{"cluster": ["monitor","manage_index_templates"],"indices": [{"names": ["radiuslogs","dhcplogs"],"privileges": ["write","create_index"],"field_security": {"grant": ["*"]}}],"run_as": [],"metadata": {},"transient_metadata": {"enabled": true}}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Create logstash_writer user in elasticsearch
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_security/user/logstash_writer?pretty'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: POST
    body: '{"username": "logstash_writer","roles": ["logstash_writer_role"],"full_name": null,"email": null,"password": "{{ logstash_writer_user_password }}","enabled": true}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Create ILM policy for wifimon in elasticsearch
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_ilm/policy/wifimon_policy?pretty'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"policy": {"phases": {"delete": {"min_age": "1d","actions": {"delete": {}}}}}}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Create radiuslogs/dhcplogs templates 
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_template/wifimon_template?pretty'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"index_patterns": ["radiuslogs", "dhcplogs"],"settings": {"index.lifecycle.name": "wifimon_policy"}}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Enable and start kibana service
  service:
    name: kibana 
    enabled: yes
    state: started
  register: kibana_service_status
  until: kibana_service_status is not failed
  delay: 30
  retries: 2

- name: Wait for kibana service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-kibana.{{ was_server_domainname }}/api/status'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: HEAD
    force_basic_auth: yes
    timeout: 10
    status_code: 200
  register: kibana_status
  until: kibana_status.status == 200
  delay: 30
  retries: 10
  no_log: true

- name: Enable and start logstash service
  service:
    name: logstash
    enabled: yes
    state: started
  register: logstash_service_status
  until: logstash_service_status is not failed
  delay: 30
  retries: 2

- name: Wait for logstash service to become up and running
  uri:
    url: 'http://localhost:9600/?pretty'
    method: HEAD
    timeout: 10
    status_code: 200
  register: logstash_status
  until: logstash_status.status == 200
  delay: 30
  retries: 10

- name: Create streams.conf.d nginx directory
  file:
    path: /etc/nginx/streams.conf.d
    state: directory
    mode: '0755'

- name: Enable logstash stream-proxy nginx configuration files
  file:
    src: /etc/nginx/sites-available/logstash-stream-proxy.conf
    dest: /etc/nginx/streams.conf.d/logstash-stream-proxy.conf
    owner: root
    group: root
    state: link

- name: Include logstash stream-proxy configuration in nginx.conf
  lineinfile:
    path: /etc/nginx/nginx.conf
    line: include /etc/nginx/streams.conf.d/*.conf;

- name: Reload nginx service
  service:
    name: nginx
    state: reloaded

- name: Modify wifimon/elasticsearch.sh script for x-pack
  replace:
    path: /usr/lib/wifimon/elasticsearch.sh
    regexp: "{{ item.regexp1 }}"
    replace: "{{ item.replace }}"
  with_items:
    - { regexp1: 'curl', replace: 'curl -s -m 15 --connect-timeout 10 -uelastic:"{{ elastic_elasticsearch_password }}"'}
    - { regexp1: 'http://localhost', replace: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}'}
    - { regexp1: ':9200', replace: ''}
  no_log: true

- name: Create wifimon elasticsearch indices
  command:
    cmd: sh /usr/lib/wifimon/elasticsearch.sh

- name: Tell elasticsearch that it is running on single node (do not enter in yellow status because of replica 0)
  uri:
    url: 'https://{{ was_server_hostname }}-elastic.{{ was_server_domainname }}/_all/_settings?preserve_existing=false'
    user: elastic
    password: "{{ elastic_elasticsearch_password }}"
    method: PUT
    body: '{"index.number_of_replicas" : "0"}'
    force_basic_auth: yes
    body_format: json
    timeout: 10
  no_log: true

- name: Enable and start wifimon service
  systemd:
    daemon_reload: yes
    name: wifimon
    state: started
    enabled: yes

- name: Wait for wifimon service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-ui.{{ was_server_domainname }}/login'
    method: HEAD
    timeout: 10
  register: wifimon_http_get_code
  until: wifimon_http_get_code.status == 200
  delay: 30
  retries: 10

- name: Import wifimon dashboards into kibana
  shell: |
    curl -f -m 30 --connect-timeout 10 -u elastic:"{{ elastic_elasticsearch_password }}" -H "kbn-xsrf: true" --form file=@/usr/lib/wifimon/kibana-import.ndjson -X POST 'https://{{ was_server_hostname }}-kibana.{{ was_server_domainname }}/api/saved_objects/_import'
  no_log: true

- name: Copy flask systemd unit file
  copy:
    src: files/flask.service
    dest: /etc/systemd/system/flask.service
    owner: root
    group: root
    mode: '0644'

- name: Enable and start flask service
  systemd:
    daemon_reload: yes
    name: flask
    state: started
    enabled: yes

- name: Wait for flask service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-flask.{{ was_server_domainname }}'
    method: HEAD
    timeout: 10
  register: flask_http_get_code
  until: flask_http_get_code.status == 200
  delay: 30
  retries: 3

- name: Install hampel python package
  shell: |
    PIP_BREAK_SYSTEM_PACKAGES=1 pip install hampel

- name: Copy anomaly systemd unit file
  copy:
    src: files/anomaly.service
    dest: /etc/systemd/system/anomaly.service
    owner: root
    group: root
    mode: '0644'

- name: Enable and start anomaly service
  systemd:
    daemon_reload: yes
    name: anomaly
    state: started
    enabled: yes

- name: Wait for anomaly service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-anomaly.{{ was_server_domainname }}'
    method: HEAD
    timeout: 10
  register: anomaly_http_get_code
  until: anomaly_http_get_code.status == 200
  delay: 30
  retries: 3

- name: Copy looking-glass systemd unit file
  copy:
    src: files/looking-glass.service
    dest: /etc/systemd/system/looking-glass.service
    owner: root
    group: root
    mode: '0644'

- name: Enable and start looking-glass service
  systemd:
    daemon_reload: yes
    name: looking-glass
    state: started
    enabled: yes

- name: Wait for looking-glass service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-looking-glass.{{ was_server_domainname }}'
    method: HEAD
    timeout: 10
  register: anomaly_http_get_code
  until: anomaly_http_get_code.status == 200
  delay: 30
  retries: 3

- name: Copy probe-state systemd unit file
  copy:
    src: files/probe-state.service
    dest: /etc/systemd/system/probe-state.service
    owner: root
    group: root
    mode: '0644'

- name: Enable and start probe-state service
  systemd:
    daemon_reload: yes
    name: probe-state
    state: started
    enabled: yes

- name: Wait for probe-state service to become up and running
  uri:
    url: 'https://{{ was_server_hostname }}-probe-state.{{ was_server_domainname }}'
    method: HEAD
    timeout: 10
  register: anomaly_http_get_code
  until: anomaly_http_get_code.status == 200
  delay: 30
  retries: 3

- name: WAS UI URL
  debug:
    msg:
      - 'Access your WAS UI at:   https://{{ was_server_hostname }}-ui.{{ was_server_domainname }}'
      - 'To download Raspbarry-PI OS image fro hardware probes, please visit: https://s3.grena.ge/raspbarry-image/whpv8.img.gz'
